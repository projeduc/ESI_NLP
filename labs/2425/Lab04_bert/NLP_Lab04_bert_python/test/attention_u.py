#!/usr/bin/env python
# -*- coding: utf-8 -*-

# This is a part of NLP labs, ESI, Algiers 
# --------------------------------------------------------------------
# Copyright (C) 2025 Abdelkrime Aries (kariminfo0@gmail.com)
# 
# Autors: 
#        - 2025 Abdelkrime Aries (kariminfo0@gmail.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#  
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os, sys

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from mybert.layers import ScaledDotProductAttention

Q = [
        [[0, 4], [3, 3], [3, 1], [1 , 1], [1 , 1]],
        [[0, 4], [3, 3], [3, 1], [1 , 1], [1 , 1]]
    ]

K = [
        [[0, 3], [2, 2], [3, 0]],
        [[0, 3], [2, 2], [3, 0]]
    ]

V = [
        [[2, 1, 0], [0, 1, 3], [1, 0, 1]],
        [[2, 1, 0], [0, 1, 3], [1, 0, 1]]
    ]

S = [
        [
            [8.48528137423857, 5.65685424949238, 0.0], 
            [6.363961030678928, 8.48528137423857, 6.363961030678928], 
            [2.1213203435596424, 5.65685424949238, 6.363961030678928], 
            [2.1213203435596424, 2.82842712474619, 2.1213203435596424], 
            [2.1213203435596424, 2.82842712474619, 2.1213203435596424]
        ], 
        [
            [8.48528137423857, 5.65685424949238, 0.0], 
            [6.363961030678928, 8.48528137423857, 6.363961030678928], 
            [2.1213203435596424, 5.65685424949238, 6.363961030678928], 
            [2.1213203435596424, 2.82842712474619, 2.1213203435596424], 
            [2.1213203435596424, 2.82842712474619, 2.1213203435596424]
        ]
        ]
P = [
        [
            [0.9440087350355953, 0.05579634104528681, 0.0001949239191178039], 
            [0.096691743097235, 0.8066165138055301, 0.096691743097235], 
            [0.009532460605340432, 0.32709046565193073, 0.6633770737427289], 
            [0.24825507825772308, 0.5034898434845538, 0.24825507825772308], 
            [0.24825507825772308, 0.5034898434845538, 0.24825507825772308]
        ], 
        [
            [0.9440087350355953, 0.05579634104528681, 0.0001949239191178039], 
            [0.096691743097235, 0.8066165138055301, 0.096691743097235], 
            [0.009532460605340432, 0.32709046565193073, 0.6633770737427289], 
            [0.24825507825772308, 0.5034898434845538, 0.24825507825772308], 
            [0.24825507825772308, 0.5034898434845538, 0.24825507825772308]
        ]
        ]
Y = [
        [
            [1.8882123939903086, 0.9998050760808822, 0.16758394705497823], 
            [0.290075229291705, 0.9033082569027651, 2.5165412845138255], 
            [0.6824419949534097, 0.33662292625727114, 1.6446484706985212], 
            [0.7447652347731692, 0.7517449217422769, 1.7587246087113846], 
            [0.7447652347731692, 0.7517449217422769, 1.7587246087113846]
        ], 
        [
            [1.8882123939903086, 0.9998050760808822, 0.16758394705497823], 
            [0.290075229291705, 0.9033082569027651, 2.5165412845138255], 
            [0.6824419949534097, 0.33662292625727114, 1.6446484706985212], 
            [0.7447652347731692, 0.7517449217422769, 1.7587246087113846], 
            [0.7447652347731692, 0.7517449217422769, 1.7587246087113846]
        ]
        ]
    
dY = [
        [
            [1, 2, 3], 
            [-1, -2, -3], 
            [0, 1, 0.5], 
            [1, 1, 1], 
            [2, 1, 0.25]
        ], 
        [
            [1.5, 0.5, 0.75], 
            [-1.5, -2.5, 2], 
            [1, 1.25, 1.5], 
            [2, 3, 4], 
            [-2, -1, -1.25]
        ]
        ]
    
dQ = [
        [
            [0.521374673489418, -0.2606065862566198], 
            [-0.3860464300738079, -0.3860464300738079], 
            [-0.3069551418927806, 0.6171244183335338], 
            [-0.1307382113716899, 0.39589033652840916], 
            [-0.8898343315855851, 0.5583941751396874]
        ], 
        [
            [-0.0563591151963869, 0.028429290431931153], 
            [0.9462394251224882, -0.28444554499595526], 
            [-0.49768811181216305, 1.001850982444942], 
            [0.4879500806606527, 1.0145786285607516], 
            [0.4055599533382708, -0.5160400054869025]
        ]
        ] 
    
dK = [
        [
            [1.517212013755615, 0.4764977558246411], 
            [-1.4520587824097853, -1.029324986360098], 
            [-0.06515323134582318, 0.552827230535463]
        ], 
        [
            [-2.376360961093538, -2.259659201932004], 
            [4.889918909350711, 3.7698738690273306], 
            [-2.5135579482571746, -1.5102146670953283]
        ]
        ] 
dV = [
        [
            [1.5920822267115295, 2.2006766009975074, 2.8570360539399053], 
            [0.7596493576934182, -0.1675701928994482, -1.4595529810990726], 
            [0.648268415595052, 0.9668935919019407, 0.3525169271591667]
        ], 
        [
            [1.280507948512881, 0.7387007420468319, 1.5983901935879157], 
            [-0.7991397934884343, -0.5728003449571606, 3.530313051455445], 
            [0.5186318449755531, 1.0840996029103287, 1.87129675495664]
        ]
        ]


att = ScaledDotProductAttention()

def test_Attention_forward():

    Yh = att.forward(Q, K, V)

    assert att.Ss == S

    assert att.Ps == P

    assert Yh == Y


def test_Attention_backward():

    # apply it again bcaus th tsts can b xcutd in parall
    Yh = att.forward(Q, K, V)

    dQs, dKs, dVs = att.backward(dY, alpha=0.1)

    assert dQs == dQ

    assert dKs == dK

    assert dVs == dV

